Проектирование и обучение нейронных сетей

## 1. Нейронные сети Кохонена. Задачи кластеризации. Структура сети Кохонена. Одномерная сеть Кохонена.

**Нейронные сети Кохонена** — это самоорганизующиеся карты (SOM, Self-Organizing Maps), которые выполняют кластеризацию и визуализацию многомерных данных. Основная цель сети — отображение входных данных на низкоразмерное пространство (обычно 1D или 2D) с сохранением топологической структуры.

### **Задачи кластеризации:**
- Разделение данных на группы с общими свойствами.
- Снижение размерности.
- Визуализация высокоразмерных данных.

### **Структура сети Кохонена:**
- **Входной слой**: содержит нейроны, каждый из которых соответствует одному входному признаку.
- **Карта (выходной слой)**: содержит нейроны, организованные в виде решетки (линейной или двумерной).
- **Весовые коэффициенты**: каждый нейрон карты имеет весовой вектор, соответствующий размерности входных данных.

### **Одномерная сеть Кохонена:**
- Содержит нейроны, выстроенные в одну линию.
- Используется для упрощенной кластеризации.
- Поддерживается топологическое соседство: обновляются веса нейронов, близких к победителю.

---

## 2. Нейронные сети Кохонена. Обучение сети Кохонена. Пример обучения.

### **Обучение сети Кохонена:**
Алгоритм обучения сети:
1. Инициализация весов случайными значениями.
2. Для каждого входного вектора:
   - Вычисляется расстояние между входным вектором и весами всех нейронов карты.
   - Выбирается победитель (нейрон с минимальным расстоянием).
   - Обновляются веса победителя и его соседей:
     $
     w_j(t+1) = w_j(t) + \eta(t) \cdot (x - w_j(t))
     $
     где $\eta(t)$ — коэффициент обучения, уменьшающийся со временем.
3. Повторение процесса до сходимости.

### **Пример обучения:**
1. Входные данные: \([0.1, 0.5], [0.8, 0.3], [0.4, 0.9]\).
2. Карта содержит 3 нейрона с весами: \([0.2, 0.6], [0.7, 0.2], [0.3, 0.8]\).
3. Для первого вектора \([0.1, 0.5]\):
   - Вычисляются расстояния до каждого нейрона.
   - Победителем становится нейрон с минимальным расстоянием.
   - Обновляются веса победителя и его соседей.

---

## 3. Нейронные сети Кохонена. Контекстные карты. Пример контекстной карты.

### **Контекстные карты:**
Контекстные карты — это модификация сети Кохонена, в которой используются дополнительные параметры для учета временной или пространственной информации в данных.

**Пример использования:**
- Классификация временных последовательностей (например, звуковых сигналов).
- Анализ контекстно-зависимых данных, таких как тексты или изображения с метаинформацией.

### **Пример контекстной карты:**
- Входной вектор дополняется контекстной информацией, например предыдущими значениями из временной последовательности.
- Карта обучается с учетом этой дополнительной информации, позволяя учитывать связи между событиями.

---

## 4. Сети встречного распространения. Звезды Гроссберга. Структура сети.

### **Сети встречного распространения:**
Это гибридные сети, сочетающие подходы самоорганизации (Кохонен) и ассоциативного обучения (Гроссберг). Используются для задач классификации и преобразования данных.

### **Структура сети:**
1. **Слой Кохонена**: выполняет кластеризацию входных данных.
2. **Слой Гроссберга**: связывает кластеры с выходными метками, выполняя ассоциативное обучение.

### **Звезды Гроссберга:**
- Пространственные области, соответствующие различным классам данных.
- Формируются вокруг весовых векторов слоя Гроссберга.

---

## 5. Сети встречного распространения. Нормальное функционирование. Слой Кохонена. Слой Гроссберга.

### **Нормальное функционирование:**
1. Входной вектор подается на слой Кохонена.
2. Победитель (нейрон с минимальным расстоянием) определяется на слое Кохонена.
3. Выход победителя передается на слой Гроссберга.
4. Слой Гроссберга формирует итоговый выходной вектор.

### **Функции слоев:**
- **Слой Кохонена**: кластеризация данных.
- **Слой Гроссберга**: ассоциативное связывание кластеров с выходными значениями.

---

## 6. Сети встречного распространения. Обучение слоя Кохонена. Предварительная обработка входных векторов. Выбор начальных значений весовых векторов.

### **Обучение слоя Кохонена:**
1. Инициализация весов случайными значениями.
2. Нормализация входных данных:
   $
   x' = \frac{x}{\|x\|}
   $
3. Поиск победителя (нейрона с минимальным расстоянием до входного вектора).
4. Обновление весов победителя и соседних нейронов.

### **Предварительная обработка входных векторов:**
- Нормализация данных.
- Масштабирование (например, приведение данных к диапазону \([0, 1]\)).
- Удаление выбросов.

### **Выбор начальных значений весовых векторов:**
- Случайная инициализация.
- Использование центроидов кластеров, вычисленных заранее (например, методом k-means).
- Распределение весов вдоль главных компонент данных.

---
### 7. Сети встречного распространения. Предварительная обработка входных векторов. Выбор начальных значений весовых векторов. Обучение слоя Гроссберга.

#### Предварительная обработка входных векторов:
- **Нормализация данных:**
  - Приведение данных в диапазон [0, 1] или [-1, 1].
  - Уменьшает влияние масштабов входных признаков.
- **Центрирование данных:**
  - Вычитание среднего значения из каждого признака.
  - Помогает ускорить сходимость обучения.
- **Удаление коррелированных признаков:**
  - Применение метода главных компонент (PCA) для устранения избыточности данных.

#### Выбор начальных значений весовых векторов:
- **Случайная инициализация:**
  - Задаются небольшие случайные значения, чтобы избежать симметрии в обучении.
- **Метод K-средних:**
  - Используется для предварительной кластеризации входных данных и задания центров кластеров в качестве начальных весов.
- **Равномерное распределение:**
  - Веса распределяются равномерно по диапазону возможных входных данных.

#### Обучение слоя Гроссберга:
1. **Определение целевого значения (target):**
   - Каждый выходной нейрон соответствует определённому классу.
2. **Обновление весов:**
   - Обучение проходит с учителем, используя правило коррекции ошибок:
     $
     w_j(t+1) = w_j(t) + \eta \cdot (y_{\text{target}} - y_{\text{predicted}}),
     $
     где $\eta$ — скорость обучения.
3. **Условие остановки:**
   - Алгоритм завершается, когда ошибка на выходе становится меньше заданного порога или достигается максимальное число итераций.

---

### 8. Рекуррентные сети. Сети Хопфилда. Структура сети Хопфилда.

#### Структура сети Хопфилда:
- **Сеть Хопфилда** представляет собой полностью связанную рекуррентную нейронную сеть.
- Все нейроны взаимосвязаны и выполняют функции как входных, так и выходных.
- **Особенности структуры:**
  - Веса симметричны: $w_{ij} = w_{ji}$.
  - На диагонали весовой матрицы значения равны нулю: $w_{ii} = 0$.
- Состояние каждого нейрона определяется правилом пороговой активации:
  $
  s_i = \begin{cases} 
  1, & \text{если } \sum_j w_{ij}s_j > \theta_i, \\
  -1, & \text{иначе},
  \end{cases}
  $
  где $\theta_i$ — пороговое значение.

#### Применение:
- Сеть используется для решения задач ассоциативной памяти и восстановления изображений с шумами.

---

### 9. Рекуррентные сети. Сети Хопфилда. Алгоритм формирования матрицы синаптических весов.

#### Алгоритм формирования весовой матрицы:
1. **Обучение сети:**
   - Сеть обучается запоминанию набора бинарных образов $\{x^p\}$, где $(x^p \in \{-1, 1\}^N)$.
2. **Формула вычисления весов:**
   $
   w_{ij} = \frac{1}{N} \sum_{p=1}^P x_i^p x_j^p,
   $
   где $(P)$ — количество запоминаемых образов.
3. **Условие симметрии:**
   - Обеспечивается автоматически формулой вычисления весов.
4. **Обнуление диагональных элементов:**
   $
   w_{ii} = 0 \text{ для всех } i.
   $

#### Свойства:
- Матрица весов симметрична и позволяет сети Хопфилда стабилизироваться в одном из обученных состояний.

---

### 10. Рекуррентные сети. Сеть Хемминга. Структура сети Хемминга.

#### Структура сети Хемминга:
- Сеть состоит из двух слоёв:
  1. **Слой вычисления расстояний:**
     - Сравнивает входной вектор с эталонными образами и вычисляет их схожесть.
  2. **Распознающий слой:**
     - Определяет, какой из эталонов наиболее близок к входному вектору.
- Используется метрика Хемминга для оценки расстояния между векторами.

#### Основные особенности:
- Нейроны слоя вычисления расстояний используют правило:
  $
  d_i = \sum_{j} (x_j \cdot w_{ij}).
  $
- В распознающем слое применяется механизм конкурентного подавления, чтобы выбрать единственный активный нейрон.

#### Применение:
- Распознавание и классификация данных с использованием кодов, устойчивых к шумам.

---

### 11. Рекуррентные сети. Сеть Элмана. Схема и общий вид нейронной сети Элмана. Модификации схемы работы сети Элмана.

#### Схема и структура:
- Сеть Элмана включает три основных слоя:
  1. **Входной слой:**
     - Принимает входные данные.
  2. **Скрытый слой:**
     - Обрабатывает входные данные и использует контекстный слой для сохранения предыдущего состояния.
  3. **Контекстный слой:**
     - Сохраняет копию значений скрытого слоя для передачи в следующий временной шаг.
- На выходе сети формируется результат на основе скрытого состояния.

#### Уравнения:
- Обновление состояния скрытого слоя:
  $
  h(t) = f(W_x x(t) + W_h h(t-1) + b),
  $
  где $(f)$ — функция активации, $(W_x)$ и $(W_h)$ — матрицы весов.
- Выходной слой:
  $
  y(t) = g(W_y h(t) + c),
  $
  где $(g)$ — функция активации выходного слоя.

#### Модификации:
- **Сеть Джордана:**
  - Контекстный слой формируется из выходных данных вместо скрытых.
- **Двухслойная структура:**
  - Добавление дополнительного скрытого слоя для повышения выразительности модели.

#### Применение:
- Анализ временных рядов, обработка последовательных данных и моделирование зависимостей с временной задержкой.

---


### 12. Рекуррентные сети. Метод обучения рекуррентной нейронной сети. Функция softmax.

#### Метод обучения RNN:
- Обратное распространение ошибки во времени (BPTT)
- Градиентный спуск с учетом временной зависимости

#### Функция softmax:
$
softmax(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}}
$
- Преобразует выходы в вероятности
- Сумма всех выходов равна 1
- Используется для многоклассовой классификации

### 13. Рекуррентные сети. Глубокие рекуррентные нейронные сети.

#### Особенности глубоких RNN:
- Множество рекуррентных слоев
- Каждый слой обрабатывает выход предыдущего
- Повышенная способность к абстракции
- Сложность в обучении из-за проблемы затухающих градиентов

### 14. Рекуррентные сети. Двунаправленные рекуррентные нейронные сети. Блоки с утечками.

#### Двунаправленные RNN:
- Обработка последовательности в обоих направлениях
- Два независимых рекуррентных слоя
- Объединение информации из обоих направлений

#### Блоки с утечками:
- Механизм сохранения долговременных зависимостей
- Постоянный поток градиента
- Простая альтернатива LSTM

### 15. Рекуррентные сети. Вентильные рекуррентные нейронные сети. Долгая краткосрочная память

#### LSTM (Long Short-Term Memory):
- Входной вентиль
- Вентиль забывания
- Выходной вентиль
- Ячейка памяти

Формулы LSTM:
$
f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)
$
$
i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)
$
$
c_t = f_t \cdot c_{t-1} + i_t \cdot \tanh(W_c \cdot [h_{t-1}, x_t] + b_c)
$

### 16. Сверточные сети. Биологическая мотивация. Примеры тензоров. Четырехмерный тензор.

#### Биологическая мотивация:
- Основана на работе зрительной коры
- Локальные рецептивные поля
- Иерархическая организация

#### Тензоры в CNN:
- 2D: изображение (высота × ширина)
- 3D: цветное изображение (высота × ширина × каналы)
- 4D: батч изображений (батч × высота × ширина × каналы)

### 17. Сверточные сети. Операция свертки. Пример двумерной свертки. Эффекты границ, дополнение и шаг свертки

#### Операция свертки:
$
(f * g)[n] = \sum_{m=-\infty}^{\infty} f[m]g[n-m]
$

#### Дополнение (padding):
- Valid: без дополнения
- Same: с дополнением для сохранения размерности
- Full: максимальное дополнение

#### Шаг свертки (stride):
- Определяет смещение фильтра
- Влияет на размер выходной карты признаков

### 18. Реализация сверточных сетей. Выбор максимального значения из соседних. Пример max-пулинга. Инвариантность.

#### Max-пулинг:
- Выбор максимального значения из области
- Уменьшение размерности
- Инвариантность к небольшим сдвигам

#### Пример max-пулинга:
$
\begin{bmatrix} 
1 & 2 & 3 & 4 \\
5 & 6 & 7 & 8 \\
9 & 10 & 11 & 12 \\
13 & 14 & 15 & 16
\end{bmatrix} \rightarrow \begin{bmatrix}
6 & 8 \\
14 & 16
\end{bmatrix}
$

### 19. Реализация сверточных сетей. Обучение. Пример выделения признаков на двух сверточных слоях.

#### Процесс обучения:
- Прямое распространение через сверточные слои
- Обратное распространение ошибки
- Обновление весов фильтров

#### Выделение признаков:
- Первый слой: простые признаки (края, углы)
- Второй слой: сложные признаки (текстуры, формы)

### 20. Архитектуры сверточных сетей. Схема сети VGG-16.

#### Архитектура VGG-16:
- 13 сверточных слоев
- 3 полносвязных слоя
- 5 блоков max-pooling
- Размер фильтра 3×3
- Общее количество параметров: 138M

### 21. Архитектуры сверточных сетей. Архитектура Inception. Общая схема сети GoogLeNet.

#### Inception модуль:
- Параллельные свертки разных размеров
- 1×1 свертки для уменьшения размерности
- Конкатенация результатов

#### GoogLeNet:
- 22 слоя с параметрами
- 9 модулей Inception
- Вспомогательные классификаторы

### 22. Архитектуры сверточных сетей. Сети ResNet.

#### Особенности ResNet:
- Остаточные блоки
- Пропускные соединения
- Формула: H(x) = F(x) + x
- Решение проблемы затухающих градиентов

### 23. Оптимизация в обучении глубоких моделей. Отличие машинного обучения от чистой оптимизации.

#### Ключевые отличия:
- Цель: обобщение vs минимизация
- Стохастичность данных
- Переобучение
- Регуляризация

### 24. Оптимизация в обучении глубоких моделей. Пакетные и мини-пакетные алгоритмы.

#### Пакетные алгоритмы:
- Использование всего набора данных
- Точный градиент
- Высокие требования к памяти

#### Мини-пакетные алгоритмы:
- Подмножество данных
- Стохастический градиент
- Быстрая сходимость

### 25. Оптимизация в обучении глубоких моделей. Проблемы оптимизации нейронных сетей.

#### Основные проблемы:
- Локальные минимумы
- Седловые точки
- Затухающие градиенты
- Взрывающиеся градиенты
- Плато

### 26. Оптимизация в обучении глубоких моделей. Основные алгоритмы. Стохастический градиентный спуск.

#### SGD:
$
\theta_{t+1} = \theta_t - \eta \nabla f_i(\theta_t)
$
- Случайный выбор примеров
- Простота реализации
- Шумная траектория оптимизации

### 27. Оптимизация в обучении глубоких моделей. Импульсный метод.

#### Momentum:
$
v_{t+1} = \mu v_t - \eta \nabla f(\theta_t)
$
$
\theta_{t+1} = \theta_t + v_{t+1}
$
- Накопление момента движения
- Преодоление локальных минимумов
- Ускорение сходимости

### 28. Алгоритмы с адаптивной скоростью обучения. Алгоритм AdaGrad.

#### AdaGrad:
$
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \odot g_t
$
- Адаптивная скорость для каждого параметра
- Накопление квадратов градиентов
- Автоматическое уменьшение шага

### 29. Алгоритмы с адаптивной скоростью обучения. Алгоритм RMSProp.

#### RMSProp:
$
E[g^2]_t = 0.9E[g^2]_{t-1} + 0.1g_t^2
$
$
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t
$
- Экспоненциальное скользящее среднее
- Нормализация градиентов
- Предотвращение затухания скорости

### 30. Алгоритмы с адаптивной скоростью обучения. Алгоритм Adam.

#### Adam:
$
m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t
$
$
v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2
$
- Сочетание momentum и RMSProp
- Коррекция смещения
- Адаптивные моменты

### 31. Методы обучения глубоких сетей. Метод Ньютона.

#### Метод Ньютона:
$
\theta_{t+1} = \theta_t - [H_f(\theta_t)]^{-1}\nabla f(\theta_t)
$
- Использует вторые производные (матрица Гессе)
- Квадратичная сходимость
- Высокая вычислительная сложность

### 32. Методы обучения глубоких сетей. Метод сопряженных градиентов.

#### Метод сопряженных градиентов:
- Поиск минимума вдоль сопряженных направлений
- Не требует хранения матрицы Гессе
- Эффективен для квадратичных функций
$
d_{t+1} = -\nabla f(\theta_t) + \beta_t d_t
$

### 33. Методы обучения глубоких сетей. Алгоритм BFGS.

#### Алгоритм BFGS:
- Квазиньютоновский метод
- Аппроксимация обратной матрицы Гессе
- Формула обновления:
$
B_{t+1} = B_t + \frac{y_ty_t^T}{y_t^Ts_t} - \frac{B_ts_ts_t^TB_t}{s_t^TB_ts_t}
$

### 34. Стратегии оптимизации и метаалгоритмы. Пакетная нормировка.

#### Batch Normalization:
- Нормализация активаций внутри мини-батча
- Уменьшение внутреннего ковариационного сдвига
- Формула:
$
y = \gamma\frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}} + \beta
$

### 35. Капсульная нейронная сеть. Эквивариантные свойства. Капсула.

#### Капсульные сети:
- Сохранение пространственных отношений
- Векторные представления признаков
- Динамическая маршрутизация
- Эквивариантность к преобразованиям

#### Структура капсулы:
- Вектор активации
- Матрица преобразования
- Алгоритм динамической маршрутизации

### 36. Глубокие капсульные нейронные сети. Схема работы слоя ConvCaps3D.

#### ConvCaps3D:
- Трехмерная свертка капсул
- Пространственная маршрутизация
- Сохранение глубинной информации
- Иерархическая организация капсул

#### Особенности работы:
- Параллельная обработка капсул
- Многомерная маршрутизация
- Агрегация информации по глубине
- Сохранение пространственных зависимостей

