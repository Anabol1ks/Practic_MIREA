\[
f(x_1,x_2)=x_1^2+x_1x_2+x_2^2+2x_1+3x_2.
\]

В этом методе на каждом шаге вычисляется градиент функции, затем определяется оптимальный шаг вдоль направления антиградиента (то есть выполняется точный поиск по направлению спуска). Для квадратной функции оптимальный шаг можно вычислить аналитически по формуле

\[
t = \frac{\|\nabla f(x)\|^2}{\nabla f(x)^T H \nabla f(x)},
\]

где \(H\) – матрица Гессе, для данной функции она равна

\[
H=\begin{pmatrix}2 & 1\\1 & 2\end{pmatrix}.
\]

Аналитическое решение системы уравнений \(\nabla f(x)=0\) показывает, что минимум достигается в точке

\[
x_1=-\tfrac{1}{3},\quad x_2=-\tfrac{4}{3},
\]

а минимальное значение функции равно

\[
f\left(-\tfrac{1}{3},-\tfrac{4}{3}\right)=-\tfrac{7}{3}\approx-2.333333.
\]

Ниже приведён исходный код с подробным выводом по каждой итерации:

---

### **Объяснение работы метода наискорейшего градиентного спуска**

Метод наискорейшего градиентного спуска является методом первого порядка, который использует информацию о градиенте для поиска минимума функции. Основная идея состоит в следующем:

1. **Начало с исходной точки.**  
   Выбирается стартовая точка \((x_0, y_0)\).

2. **Вычисление градиента.**  
   Для текущей точки вычисляется градиент функции  
   \[
   \nabla f(x,y)=\begin{pmatrix}2x+y+2\\x+2y+3\end{pmatrix}.
   \]
   Градиент указывает направление наибольшего возрастания, поэтому для спуска берётся отрицательный градиент.

3. **Определение оптимального шага (точный поиск по линии).**  
   В методе наискорейшего спуска шаг выбирается так, чтобы минимизировать функцию вдоль направления антиградиента. Для квадратичной функции можно аналитически вывести оптимальный шаг по формуле:
   \[
   t = \frac{\|\nabla f(x)\|^2}{\nabla f(x)^T H \nabla f(x)},
   \]
   где \(H\) — матрица Гессе функции. Для нашей функции \(H=\begin{pmatrix}2 & 1\\1 & 2\end{pmatrix}\).

4. **Обновление текущей точки.**  
   Новая точка находится по правилу:
   \[
   x_{\text{new}} = x_{\text{old}} - t\,\nabla f(x_{\text{old}}).
   \]

5. **Проверка критерия сходимости.**  
   Если норма градиента становится меньше заданного порога \(tol\), алгоритм завершается.

---

### **Объяснение кода**

1. **Функция f:**  
   Функция `f(x, y)` вычисляет значение целевой функции  
   
   \[
   x^2+xy+y^2+2x+3y.
   \]

2. **Функция steepestDescent:**  
   Эта функция реализует метод наискорейшего градиентного спуска:
   - **Вычисление градиента.**  
     Вычисляются компоненты градиента:
     ```go
     gradX := 2*x + y + 2
     gradY := x + 2*y + 3
     ```
   - **Проверка сходимости.**  
     Если норма градиента меньше заданного порога `tol`, алгоритм останавливается.
   - **Вычисление оптимального шага.**  
     Оптимальный шаг \(t\) вычисляется по формуле:
     ```go
     t := gradNormSq / (2 * (gradX*gradX + gradX*gradY + gradY*gradY))
     ```
     где `gradNormSq` — квадрат нормы градиента.
   - **Обновление текущей точки.**  
     Новая точка определяется по правилу:
     ```go
     x = x - t*gradX
     y = y - t*gradY
     ```
   - **Вывод промежуточных данных.**  
     На каждой итерации выводятся номер итерации, текущая точка, значение функции, градиент и выбранный шаг.

3. **Функция main:**  
   Здесь задаются начальные параметры (начальная точка, точность, максимальное число итераций), запускается алгоритм и выводится результат. Дополнительно производится сравнение с аналитически полученным минимумом для проверки корректности вычислений.

Таким образом, данный код демонстрирует применение метода наискорейшего градиентного спуска для минимизации функции первого порядка с точным поиском оптимального шага на каждом шаге спуска.